{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d1253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b88aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "import streamlit as st\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title\n",
    "st.title('Secure Pay Guard: Credit Card Fraud Detection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4687fc7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Read Data into a Dataframe\n",
    "#using the smaller file for sample to upload easily on github\n",
    "df = pd.read_csv('creditcard_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38310194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1 CHECKBOX ---\n",
    "if st.sidebar.checkbox('Show the initial data set'):\n",
    "    st.header(\"Understanding dataset\")\n",
    "    st.write('Initial data set: \\n', df)\n",
    "    st.write('Data decription: \\n', df.describe())\n",
    "    st.write('Shape of the dataframe: ', df.shape)\n",
    "    st.write('Missing values: ', df.isnull().values.sum())\n",
    "    st.write('Duplicate rows: ', df.duplicated(keep=False).sum())\n",
    "    df = df.drop_duplicates() \n",
    "    st.write('New data set after removing duplicates:', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2 CHECKBOX ---\n",
    "if st.sidebar.checkbox('Show the analysis'):\n",
    "    fraud = df[df.Class == 1]\n",
    "    valid = df[df.Class == 0]\n",
    "    outlier_percentage = (df.Class.value_counts()[1]/df.Class.value_counts()[0])*100\n",
    "\n",
    "    st.header('Univariate analysis')\n",
    "    st.write('Fraud Cases: ', len(fraud))\n",
    "    st.write('Valid Cases: ', len(valid))\n",
    "    st.write('Fraudulent transactions are: %.3f%%' % outlier_percentage)\n",
    "\n",
    "    def countplot_data(data, feature):\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        sns.countplot(x=feature, data=data)\n",
    "        st.pyplot(plt.gcf())\n",
    "\n",
    "    st.subheader('Transaction ratio:')\n",
    "    countplot_data(df, df.Class)\n",
    "\n",
    "    def graph2():\n",
    "        f, axes = plt.subplots(ncols=2, figsize=(12, 5))\n",
    "        colors = ['#C35617', '#FFDEAD']\n",
    "        sns.boxplot(x=\"Class\", y=\"Amount\", data=df, palette=colors, ax=axes[0], showfliers=True)\n",
    "        axes[0].set_title('With outliers')\n",
    "        sns.boxplot(x=\"Class\", y=\"Amount\", data=df, palette=colors, ax=axes[1], showfliers=False)\n",
    "        axes[1].set_title('Without outliers')\n",
    "        st.pyplot(f)\n",
    "\n",
    "    st.subheader('Boxplots for Class vs Amount')\n",
    "    graph2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6446f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3 CHECKBOX ---\n",
    "if st.sidebar.checkbox('Model building on imbalanced data'):\n",
    "    st.header('Train and test split')\n",
    "    X = df.drop(['Class'], axis=1)\n",
    "    y = df['Class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train['Amount'] = scaler.fit_transform(X_train[['Amount']])\n",
    "    X_test['Amount'] = scaler.transform(X_test[['Amount']])\n",
    "\n",
    "    cols = X_train.columns\n",
    "    pt = PowerTransformer(method='yeo-johnson', standardize=True, copy=False)\n",
    "    X_train[cols] = pt.fit_transform(X_train)\n",
    "    X_test[cols] = pt.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcccfc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4 CHECKBOX ---\n",
    "if st.sidebar.checkbox('Compare algorithms'):\n",
    "    X = df.drop(['Class'], axis=1)\n",
    "    y = df['Class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train['Amount'] = scaler.fit_transform(X_train[['Amount']])\n",
    "    X_test['Amount'] = scaler.transform(X_test[['Amount']])\n",
    "    cols = X_train.columns\n",
    "    pt = PowerTransformer(method='yeo-johnson', standardize=True, copy=False)\n",
    "    X_train[cols] = pt.fit_transform(X_train)\n",
    "    X_test[cols] = pt.transform(X_test)\n",
    "\n",
    "    def visualize_confusion_matrix(y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='g', cmap='Oranges')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        st.pyplot(plt.gcf())\n",
    "\n",
    "    def ROC_AUC(Y, Y_prob):\n",
    "        fpr, tpr, _ = roc_curve(Y, Y_prob)\n",
    "        model_auc = roc_auc_score(Y, Y_prob)\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.plot(fpr, tpr, label='AUC=%.3f' % model_auc)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend()\n",
    "        st.pyplot(plt.gcf())\n",
    "\n",
    "    # Logistic Regression\n",
    "    st.header('Logistic Regression')\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "    st.text(classification_report(y_test, pred))\n",
    "    visualize_confusion_matrix(y_test, pred)\n",
    "    ROC_AUC(y_test, proba)\n",
    "\n",
    "    # Decision Tree (chosen as second model)\n",
    "    st.header('Decision Tree')\n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    proba = model.predict_proba(X_test)[:, 1]\n",
    "    st.text(classification_report(y_test, pred))\n",
    "    visualize_confusion_matrix(y_test, pred)\n",
    "    ROC_AUC(y_test, proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5 CHECKBOX ---\n",
    "if st.sidebar.checkbox('Manual transaction verification'):\n",
    "    legit = df[df.Class == 0]\n",
    "    fraud = df[df.Class == 1]\n",
    "    legit_sample = legit.sample(n=len(fraud), random_state=2)\n",
    "    data = pd.concat([legit_sample, fraud], axis=0)\n",
    "    X = data.drop(columns=\"Class\", axis=1)\n",
    "    y = data[\"Class\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    st.title(\"Manual transaction verification\")\n",
    "    st.write(\"Input the 30 feature values (excluding Class) separated by commas:\")\n",
    "    input_df = st.text_input('Input All features')\n",
    "    input_df_lst = input_df.split(',')\n",
    "    submit = st.button(\"Submit\")\n",
    "    if submit:\n",
    "        features = np.array(input_df_lst, dtype=np.float64)\n",
    "        prediction = model.predict(features.reshape(1, -1))\n",
    "        if prediction[0] == 0:\n",
    "            st.success(\"Legitimate transaction\")\n",
    "        else:\n",
    "            st.error(\"Fraudulent transaction\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
